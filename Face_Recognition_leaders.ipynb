{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Face_Recognition_leaders.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNjP8+J4bYLeFqMnkX9JcO9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/princetyagitech/Computer_Vision/blob/master/Face_Recognition_leaders.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7hks12Y9o0y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "52169508-e6d8-4e83-881c-3321aa7955d8"
      },
      "source": [
        "! pip install face_recognition"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting face_recognition\n",
            "  Downloading https://files.pythonhosted.org/packages/1e/95/f6c9330f54ab07bfa032bf3715c12455a381083125d8880c43cbe76bb3d0/face_recognition-1.3.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from face_recognition) (7.0.0)\n",
            "Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.6/dist-packages (from face_recognition) (7.1.2)\n",
            "Collecting face-recognition-models>=0.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cf/3b/4fd8c534f6c0d1b80ce0973d01331525538045084c73c153ee6df20224cf/face_recognition_models-0.3.0.tar.gz (100.1MB)\n",
            "\u001b[K     |████████████████████████████████| 100.2MB 112kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from face_recognition) (1.18.5)\n",
            "Requirement already satisfied: dlib>=19.7 in /usr/local/lib/python3.6/dist-packages (from face_recognition) (19.18.0)\n",
            "Building wheels for collected packages: face-recognition-models\n",
            "  Building wheel for face-recognition-models (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for face-recognition-models: filename=face_recognition_models-0.3.0-py2.py3-none-any.whl size=100566172 sha256=e7b6ddd82fec97f860ee30eaeba9f2641ab555fa08ae8ac4c7f506266c4fdce5\n",
            "  Stored in directory: /root/.cache/pip/wheels/d2/99/18/59c6c8f01e39810415c0e63f5bede7d83dfb0ffc039865465f\n",
            "Successfully built face-recognition-models\n",
            "Installing collected packages: face-recognition-models, face-recognition\n",
            "Successfully installed face-recognition-1.3.0 face-recognition-models-0.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKOxSfE8z5M7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import face_recognition\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "video_capture = cv2.VideoCapture(0)\n",
        "\n",
        "# Load a sample picture and learn how to recognize it.\n",
        "cameron_image = face_recognition.load_image_file(\"/content/cameron.jfif\")\n",
        "cameron_face_encoding = face_recognition.face_encodings(cameron_image)[0]\n",
        "\n",
        "# Load a second sample picture and learn how to recognize it.\n",
        "modi_image = face_recognition.load_image_file(\"/content/modi.jfif\")\n",
        "modi_face_encoding = face_recognition.face_encodings(modi_image)[0]\n",
        "\n",
        "putin_image = face_recognition.load_image_file(\"/content/putin.jfif\")\n",
        "putin_face_encoding = face_recognition.face_encodings(putin_image)[0]\n",
        "\n",
        "trump_image = face_recognition.load_image_file(\"/content/trump.jpg\")\n",
        "trump_face_encoding = face_recognition.face_encodings(trump_image)[0]\n",
        "\n",
        "xi_image = face_recognition.load_image_file(\"/content/xi.jpg\")\n",
        "xi_face_encoding = face_recognition.face_encodings(xi_image)[0]\n",
        "\n",
        "# Create arrays of known face encodings and their names\n",
        "known_face_encodings = [\n",
        "    cameron_face_encoding,\n",
        "    modi_face_encoding,\n",
        "    putin_face_encoding,\n",
        "    trump_face_encoding,\n",
        "    xi_face_encoding\n",
        "]\n",
        "known_face_names = [\n",
        "    \"David Cameron\",\n",
        "    \"Narendra Modi\",\n",
        "    \"Vladimir Putin\",\n",
        "    \"Donald Trump\",\n",
        "    \"Xi JinPing\"\n",
        "]\n",
        "\n",
        "# Initialize some variables\n",
        "face_locations = []\n",
        "face_encodings = []\n",
        "face_names = []\n",
        "process_this_frame = True\n",
        "\n",
        "while True:\n",
        "    # Grab a single frame of video\n",
        "    ret, frame = video_capture.read()\n",
        "\n",
        "    # Resize frame of video to 1/4 size for faster face recognition processing\n",
        "    small_frame = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25)\n",
        "\n",
        "    # Convert the image from BGR color (which OpenCV uses) to RGB color (which face_recognition uses)\n",
        "    rgb_small_frame = small_frame[:, :, ::-1]\n",
        "\n",
        "    # Only process every other frame of video to save time\n",
        "    if process_this_frame:\n",
        "        # Find all the faces and face encodings in the current frame of video\n",
        "        face_locations = face_recognition.face_locations(rgb_small_frame)\n",
        "        face_encodings = face_recognition.face_encodings(rgb_small_frame, face_locations)\n",
        "\n",
        "        face_names = []\n",
        "        for face_encoding in face_encodings:\n",
        "            # See if the face is a match for the known face(s)\n",
        "            matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n",
        "            \n",
        "\n",
        "            # # If a match was found in known_face_encodings, just use the first one.\n",
        "            if True in matches:\n",
        "              first_match_index = matches.index(True)\n",
        "              name = known_face_names[first_match_index]\n",
        "            else:\n",
        "              name = \"Unknown\"\n",
        "\n",
        "            # Or instead, use the known face with the smallest distance to the new face\n",
        "            face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)\n",
        "            best_match_index = np.argmin(face_distances)\n",
        "            if matches[best_match_index]:\n",
        "                name = known_face_names[best_match_index]\n",
        "\n",
        "            face_names.append(name)\n",
        "\n",
        "    process_this_frame = not process_this_frame\n",
        "\n",
        "\n",
        "    # Display the results\n",
        "    for (top, right, bottom, left), name in zip(face_locations, face_names):\n",
        "        # Scale back up face locations since the frame we detected in was scaled to 1/4 size\n",
        "        top *= 4\n",
        "        right *= 4\n",
        "        bottom *= 4\n",
        "        left *= 4\n",
        "\n",
        "        # Draw a box around the face\n",
        "        cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2)\n",
        "\n",
        "        # Draw a label with a name below the face\n",
        "        cv2.rectangle(frame, (left, bottom - 35), (right, bottom), (0, 0, 255), cv2.FILLED)\n",
        "        font = cv2.FONT_HERSHEY_DUPLEX\n",
        "        cv2.putText(frame, name, (left + 6, bottom - 6), font, 1.0, (255, 255, 255), 1)\n",
        "        \n",
        "    # Display the resulting image\n",
        "    cv2.imshow('Video', frame)\n",
        "\n",
        "    # Hit 'q' on the keyboard to quit!\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "# Release handle to the webcam\n",
        "video_capture.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJgTYZx-9nBU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}